{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первичный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Первичный анализ данных \\\n",
    "1.1 Проверить уникальность id в полисах и убытках \\\n",
    "1.2 Подтянуть рисковые факторы и характеристики от полисов к убыткам \\\n",
    "1.3 Провести агрегацию выплат до убытков \\\n",
    "1.4 Подтянуть количество и сумму убытков к каждому полису \\\n",
    "1.5 Притянуть к полисам и убыткам – количество водителей, возраст самого молодого, стаж водителя с самым маленьким стажем. \\\n",
    "1.6 Провести проверки данных. Это творческое задание. Примеры проверок – дата начала полиса больше даты окончания полиса,дата убытка между датой начала и окончания полиса и т.д. \\\n",
    "1.7 Построить распределения количества убытков и размера убытка – посмотреть средние, минимальные и максимальные значения, перцентили. \\\n",
    "1.8 Рассчитать экспозицию и заработанную премию для календарного анализа \\\n",
    "1.9 Отдельно для календарного и андеррайтингово подходов (для убытков - тяжесть и полисов - частота) посмотреть по каждому фактору: \\\n",
    "1.9.1 заполненность факторов, построить распределения значений фактора (для каждого фактора) в портфеле (по таблице с полисами) \\\n",
    "1.9.2 построить графики количества убытков/тяжести убытков в зависимости от значений фактора, для каждого уровня фактора оценить дисперсию количества и тяжести; \\\n",
    "1.9.3 проанализировать устойчивость одномерных распределений по годам (убытка, заключения полиса)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Проверить уникальность id в полисах и убытках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент уникальных id полисов в реестре выплат: 76.55517854257555\n",
      "Процент уникальных id полисов в реестре полисов: 100.0\n",
      "Процент уникальных id полисов в реестре водителей: 58.260494340397095\n",
      "Процент уникальных id убытков: 100.0\n"
     ]
    }
   ],
   "source": [
    "df_claim = pd.read_excel('/workspaces/BDAktuarki/data/claim_reestr.xlsx')\n",
    "df_polis = pd.read_excel('/workspaces/BDAktuarki/data/polis_reestr.xlsx')\n",
    "df_drivers = pd.read_excel('/workspaces/BDAktuarki/data/drivers_reestr.xlsx')\n",
    "\n",
    "print(f'Процент уникальных id полисов в реестре выплат: {df_claim[\"POLIS_ID\"].nunique() / len(df_claim) * 100}')\n",
    "print(f'Процент уникальных id полисов в реестре полисов: {df_polis[\"POLIS_ID\"].nunique() / len(df_polis) * 100}')\n",
    "print(f'Процент уникальных id полисов в реестре водителей: {df_drivers[\"POLIS_ID\"].nunique() / len(df_drivers) * 100}')\n",
    "print(f'Процент уникальных id убытков: {df_claim[\"PAY_ID\"].nunique() / len(df_claim) * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Провести проверки данных. \n",
    "Это творческое задание. Примеры проверок – дата начала полиса больше даты окончания полиса, дата убытка между датой начала и окончания полиса и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE_DT\n",
      "START_DT\n",
      "END_DT\n",
      "DTP_DT\n",
      "CLAIM_DT\n",
      "PAY_DT\n"
     ]
    }
   ],
   "source": [
    "# Первичное преобразование типов для непустых признаков дат\n",
    "for col in df_polis.columns:\n",
    "    if ('_DT' in col) and (df_polis[col].isna().sum() == 0):\n",
    "        print(col)\n",
    "        df_polis[col] = pd.to_datetime(df_polis[col]) \n",
    "\n",
    "for col in df_claim.columns:\n",
    "    if ('_DT' in col) and (df_claim[col].isna().sum() == 0):\n",
    "        print(col)\n",
    "        df_claim[col] = pd.to_datetime(df_claim[col], dayfirst=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118574 entries, 0 to 118573\n",
      "Data columns (total 37 columns):\n",
      " #   Column           Non-Null Count   Dtype         \n",
      "---  ------           --------------   -----         \n",
      " 0   POLIS_ID         118574 non-null  int64         \n",
      " 1   CREATE_DT        118574 non-null  datetime64[ns]\n",
      " 2   START_DT         118574 non-null  datetime64[ns]\n",
      " 3   END_DT           118574 non-null  datetime64[ns]\n",
      " 4   PREMIUM          118573 non-null  float64       \n",
      " 5   DISSOLUTION_DT   0 non-null       float64       \n",
      " 6   VIN              108264 non-null  object        \n",
      " 7   CAR_ISSUE        118176 non-null  float64       \n",
      " 8   CAR_DIAG_DT      78205 non-null   object        \n",
      " 9   PERS_POLIS_OWN   118501 non-null  object        \n",
      " 10  PERS_CAR_OWN     118574 non-null  object        \n",
      " 11  KLADR_CODE       118164 non-null  float64       \n",
      " 12  MULTIDRIVE_FLG   118574 non-null  int64         \n",
      " 13  BONUS_MALUS      118556 non-null  float64       \n",
      " 14  CAR_ENG_PWR      118157 non-null  float64       \n",
      " 15  TRAILER_FLG      118574 non-null  int64         \n",
      " 16  CAR_WEIGHT       813 non-null     float64       \n",
      " 17  CAR_SEATS_CNT    518 non-null     float64       \n",
      " 18  USE_PURPOSE_FLG  118574 non-null  int64         \n",
      " 19  REG_COUNTRY_FLG  118574 non-null  int64         \n",
      " 20  START1           118061 non-null  object        \n",
      " 21  END1             118066 non-null  object        \n",
      " 22  START2           72 non-null      object        \n",
      " 23  END2             72 non-null      object        \n",
      " 24  START3           6 non-null       object        \n",
      " 25  END3             6 non-null       object        \n",
      " 26  hash_vin         108264 non-null  object        \n",
      " 27  LOSS_ID          6189 non-null    float64       \n",
      " 28  DTP_DT           6189 non-null    datetime64[ns]\n",
      " 29  CLAIM_DT         6189 non-null    datetime64[ns]\n",
      " 30  PAY_ID           6189 non-null    float64       \n",
      " 31  PAY_AMT          6189 non-null    float64       \n",
      " 32  PAY_DT           6189 non-null    datetime64[ns]\n",
      " 33  DAMAGE_TYPE      6189 non-null    float64       \n",
      " 34  IS_ALCHO_DMG     6189 non-null    float64       \n",
      " 35  IS_DISAPPEAR     6189 non-null    float64       \n",
      " 36  EURO_PROTOCOL    6189 non-null    float64       \n",
      "dtypes: datetime64[ns](6), float64(15), int64(5), object(11)\n",
      "memory usage: 33.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_polis_to_j = df_polis.set_index('POLIS_ID').copy()\n",
    "df_claim_to_j = df_claim.set_index('POLIS_ID').copy()\n",
    "df_j_pls_clm = df_polis_to_j.join(df_claim_to_j, how='left').reset_index()\n",
    "df_j_pls_clm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df_polis_to_j, df_claim_to_j\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент наблюдений среди случаев с ДТП в которых дата убытка между датой начала и окончания 79.30198739699466\n"
     ]
    }
   ],
   "source": [
    "# Дата начала полиса больше даты окончания полиса\n",
    "mask = df_polis['START_DT'] > df_polis['END_DT']\n",
    "assert len(df_polis[mask]) == 0\n",
    "\n",
    "# Дата убытка между датой начала и окончания полиса\n",
    "mask_on_pay = ~df_j_pls_clm['PAY_ID'].isna()\n",
    "mask_on_date_lb = df_j_pls_clm['PAY_DT'] >= df_j_pls_clm['START_DT']\n",
    "mask_on_date_lb = df_j_pls_clm['PAY_DT'] <= df_j_pls_clm['END_DT']\n",
    "print('Процент наблюдений среди случаев с ДТП в которых дата убытка между датой начала и окончания', end=' ')\n",
    "print(len(df_j_pls_clm[mask_on_pay & mask_on_date_lb & mask_on_date_lb]) / len(df_j_pls_clm[mask_on_pay]) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во наблюдений в каждом численном признаке равных 0\n",
      "polis_reestr: ('PREMIUM', 75) ('BONUS_MALUS', 0) ('CAR_ENG_PWR', 1) ('CAR_WEIGHT', 303) ('CAR_SEATS_CNT', 331)\n",
      "drivers_reestr: ('DRIVER_AGE', 0) ('DRIVER_EXP', 1131) ('BONUS_MALUS', 0)\n",
      "claim_reestr: ('PAY_AMT', 1)\n",
      "\n",
      "Кол-во наблюдений в каждом численном признаке меньше 0\n",
      "polis_reestr: ('PREMIUM', 1) ('BONUS_MALUS', 0) ('CAR_ENG_PWR', 0) ('CAR_WEIGHT', 0) ('CAR_SEATS_CNT', 0)\n",
      "drivers_reestr: ('DRIVER_AGE', 0) ('DRIVER_EXP', 2) ('BONUS_MALUS', 0)\n",
      "claim_reestr: ('PAY_AMT', 0)\n"
     ]
    }
   ],
   "source": [
    "# Проверка численных признаков на равенство положительную определенность \n",
    "num_feats_polis = ['PREMIUM', 'BONUS_MALUS', 'CAR_ENG_PWR', 'CAR_WEIGHT', 'CAR_SEATS_CNT']\n",
    "num_feats_drivers = ['DRIVER_AGE', 'DRIVER_EXP', 'BONUS_MALUS']\n",
    "num_feats_claim = ['PAY_AMT']\n",
    "num_feats_all = [num_feats_polis, num_feats_drivers, num_feats_claim]\n",
    "all_dfs = {'polis_reestr': df_polis,\n",
    "           'drivers_reestr': df_drivers,\n",
    "           'claim_reestr': df_claim}\n",
    "\n",
    "print('Кол-во наблюдений в каждом численном признаке равных 0')\n",
    "for feat_list, df_key in zip(num_feats_all, all_dfs.keys()):\n",
    "    df = all_dfs[df_key].copy()\n",
    "    lens_wrong = [len(df[df[feat] == 0]) for feat in feat_list]\n",
    "    print(df_key, end=': ')\n",
    "    print(*zip(feat_list, lens_wrong))\n",
    "print()\n",
    "print('Кол-во наблюдений в каждом численном признаке меньше 0')\n",
    "for feat_list, df_key in zip(num_feats_all, all_dfs.keys()):\n",
    "    df = all_dfs[df_key].copy()\n",
    "    lens_wrong = [len(df[df[feat] < 0]) for feat in feat_list]\n",
    "    print(df_key, end=': ')\n",
    "    print(*zip(feat_list, lens_wrong))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del all_dfs, df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7 Построить распределения количества убытков и размера убытка \n",
    "Посмотреть средние, минимальные и максимальные значения, перцентили."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
